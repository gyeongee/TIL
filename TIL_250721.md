### CNN(Convolution Neural Network) 모델 이해하기
- CNN은 Convolution 층과 Pooling 층으로 구성
- Convolution층 : 입력데이터에서 특성을 추출
- Pooling층 : 추출된 특성이미지의 크기를 축소,<span style="color: orange">채널 수는 그대로 유지</span>
  - stride:Pooling의 속도가 느리므로 stride를 이용해서 크기를 줄이기도 함
  ```python
 <center>  
<img src="https://arome1004.cafe24.com/images/pytorch/lecture_image/08_cnn9.png" width=50%>   
</center>  ```

#### 이미지가 커널 사이즈가 (3,3)이나 (5,5)를 가지는 필터를 거쳐 <span style="color: orange">특성맵(feature map) 생성</span>

#### 특성맵의 크기가 입력 사이즈와 같게 만들기 위해 padding을 설정해서 좌우 상하에 0을 넣음, <span style="color: orange">0을 n개 넣을지를 정하는게 padding = n</span>

## 코드

| 차원 순서 | 의미              | 값   | 설명                                                |
|----------|------------------|------|-----------------------------------------------------|
| `N`      | Batch size       | 1    | 한 번에 처리할 이미지 개수 (여기서는 1장)           |
| `C`      | Channel          | 1    | 채널 수 (흑백은 1, 컬러는 3)                        |
| `H`      | Height (세로)    | 28   | 이미지의 높이 (픽셀 단위)                           |
| `W`      | Width (가로)     | 28   | 이미지의 너비 (픽셀 단위)                           |

``` python
import torch 
import torch.nn as nn
# (1,1,28,28) -> 이미지개수,채널, (행,열)
# 한 번에 한 장씩 흑백 이미지 처리
inputs = torch.Tensor(1,1,28,28)
print(f"텐서의 크기 : {inputs.size()}")
## 합성곱층과 풀링층 선언

# 입력 채널 수 (흑백 이미지니까 1)
# (3,3) 필터 32개를 적용시키고 작아진 사이즈에 상하좌우에 0  한 개씩 채우겠다.
conv1 = nn.Conv2d(in_channels = 1, out_channels=32,kernel_size=3, padding=1)
h = conv1(inputs)
# Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
```
📐 공식 복습:
출력 크기 계산 공식

Output Size
=
(
𝑊
−
𝐾
+
2
𝑃
)
𝑆
+
1
Output Size= 
S
(W−K+2P)
​
 +1
𝑊
W: 입력 크기 (Width or Height)

𝐾
K: 커널 크기 (kernel_size)

𝑃
P: 패딩 (padding)

𝑆
S: 스트라이드 (stride, 보통 1)
``` python
# 2번째 합성곱층 구현
# 이전 층의 32개의 특성 이미지를 받아서 64개의 특성 이미지를 추출
# padding : 합성곱 연산 이후에도 특성 맵의 크기가 입력의 크기가 동일하게 유지되도록 하는 것
conv2 = nn.Conv2d(32,64,kernel_size=3,padding=1)
# Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
pool = nn.MaxPool2d(kernel_size=2)
#MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)


#구현한 층 연결
# 1층 연결
h = conv1(inputs) # torch.Size([1, 32, 28, 28])
h = pool(h)       # torch.Size([1, 32, 14, 14])

# 2층연결
h = conv2(h)      # torch.Size([1, 64, 14, 14])
h = pool(h)       # torch.Size([1, 64, 7, 7])
 
```
### 분류기에 연결하기 위해 출력텐서를 1차원으로 변환
``` python
# 첫 번째 차원인 배치 차원은 그대로 두고 나머지는 1차원으로 변환
h = h.view(h.size(0),-1) # 결과 :h.shape(1,64 x 7 x 7)
```
### 분류기 구현
```python
fc = nn.Linear(h.size(-1),0)
h = fc(h)  # torch.Size([1, 10])
```
