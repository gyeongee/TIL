{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "17b_NZ6gXl3xB7klCPWrXwGmoQP-jPUL-",
      "authorship_tag": "ABX9TyPeao+GiDWb/o2F19BVvJMX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b67bee8bdce4eb1b00c465244707529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9dd3f794d7f422f995acbf68c511c4a",
              "IPY_MODEL_f7b9edc064c2408d8d545b4757f0ed11",
              "IPY_MODEL_b302a2fc5d4b4ce99a7d548454dde3f6"
            ],
            "layout": "IPY_MODEL_56785b1047034e038222333c25c958b1"
          }
        },
        "d9dd3f794d7f422f995acbf68c511c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acabe1376f9b4b8c83e11aea91ecf5e5",
            "placeholder": "​",
            "style": "IPY_MODEL_18d5711367794c7c9442325688b5556c",
            "value": "deepfake_gnn_model.pth: 100%"
          }
        },
        "f7b9edc064c2408d8d545b4757f0ed11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_157a5d4505b546f7b61059a63d983952",
            "max": 792857,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a02bef9c46f4674b34a980ea53b6959",
            "value": 792857
          }
        },
        "b302a2fc5d4b4ce99a7d548454dde3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5099ec985aa47e3b0b711525e844919",
            "placeholder": "​",
            "style": "IPY_MODEL_c72496fd202c451091240cae553924b5",
            "value": " 793k/793k [00:01&lt;00:00, 1.74MB/s]"
          }
        },
        "56785b1047034e038222333c25c958b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acabe1376f9b4b8c83e11aea91ecf5e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d5711367794c7c9442325688b5556c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "157a5d4505b546f7b61059a63d983952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a02bef9c46f4674b34a980ea53b6959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5099ec985aa47e3b0b711525e844919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72496fd202c451091240cae553924b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyeongee/TIL/blob/main/TIL_250821.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/인사교_8월미니프로젝트'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9nO62us5Ogx",
        "outputId": "1cde68a0-aa8a-453e-896d-88b08b2e6378"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/인사교_8월미니프로젝트\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_gaWr9kBmav",
        "outputId": "142e874a-2d90-4c44-c99a-64d44ba8c508"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  deepfake-detection-clip-gnn.ipynb  deepfake_gnn_model.pth  dmsrud  key\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "with open(\"./key/huggingface_api_key\",'r') as f:\n",
        "  api_key = f.read().strip()\n",
        "\n",
        "  login(token=api_key)"
      ],
      "metadata": {
        "id": "aSwtfjAGBGRZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTKiarqcciEd",
        "outputId": "c6886a01-63b6-4aec-89b9-7e66fe2180f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m318.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install torch-geometric\n",
        "!pip install transformers\n",
        "!pip install opencv-python\n",
        "!pip install scikit-learn\n",
        "!pip install seaborn\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from torch_geometric.data import Data as GeoData, Batch\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "E5Np2atecuKI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE = 4\n",
        "LR = 0.0001\n",
        "EPOCHS = 5\n",
        "PATCH_SIZE = 32\n",
        "CLIP_DIM = 512 # 입력 feature size: 196×512\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "KkcRX9p1c3kB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "XRE4M76Mc8Up"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPModel\n",
        "\n",
        "# 1. CLIP 모델 불러오기\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "clip_processor=CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ],
      "metadata": {
        "id": "rk9O8rlhvfPc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_bmDIuRf2vmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GNN Model Definition --------------------------------------------------\n",
        "class DeepfakeGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        # 마지막 classification layer\n",
        "        # 1 (이진 분류: real/fake)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        # 그래프 단위로 feature 평균 pooling\n",
        "        # batch: 노드별로 어떤 그래프에 속하는지 나타내는 인덱스\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return self.fc(x).squeeze(-1)"
      ],
      "metadata": {
        "id": "_mZBkQ0VdAQ8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize GNN\n",
        "model = DeepfakeGNN(CLIP_DIM, 256).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "-HH0PGdOdyKL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing ---------------------------------------------------\n",
        "def extract_patches(image_tensor, patch_size=PATCH_SIZE):\n",
        "    \"\"\"Convert image tensor to patches\"\"\"\n",
        "    patches = []\n",
        "    coords = []\n",
        "    for i in range(0, 224, patch_size):\n",
        "        for j in range(0, 224, patch_size):\n",
        "            patch = image_tensor[:, i:i+patch_size, j:j+patch_size]\n",
        "            patches.append(patch)\n",
        "            coords.append([i, j])\n",
        "    return patches, coords\n",
        "\n",
        "def create_graph(coords, threshold=1.5*PATCH_SIZE):\n",
        "    \"\"\"Create edges between nearby patches\"\"\"\n",
        "    edges = []\n",
        "    for i, (x1, y1) in enumerate(coords):\n",
        "        for j, (x2, y2) in enumerate(coords):\n",
        "            if ((x1-x2)**2 + (y1-y2)**2) <= threshold**2:\n",
        "                edges.append([i, j])\n",
        "    return torch.tensor(edges, dtype=torch.long).t().contiguous()"
      ],
      "metadata": {
        "id": "DjXLGz8Wd1Dg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "\n",
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.dataset = datasets.ImageFolder(root_dir, transform=transform)\n",
        "        self.classes = self.dataset.classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.dataset[idx]\n",
        "\n",
        "        # 1. Extract patches\n",
        "        patches, coords = extract_patches(img)\n",
        "\n",
        "        # 2. Convert patches to numpy images for CLIP\n",
        "        images = []\n",
        "        for p in patches:\n",
        "            np_patch = (p.detach().cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8)\n",
        "            images.append(np_patch)\n",
        "\n",
        "        # 3. CLIP features\n",
        "        with torch.no_grad():\n",
        "            inputs = clip_processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
        "            patch_features = clip_model.get_image_features(**inputs)\n",
        "\n",
        "        # 4. Graph\n",
        "        edge_index = create_graph(coords)\n",
        "\n",
        "        return GeoData(\n",
        "            x=patch_features,\n",
        "            edge_index=edge_index,\n",
        "            y=torch.tensor(label, dtype=torch.float)\n",
        "        )"
      ],
      "metadata": {
        "id": "Pn0Jy2OAd6f3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize datasets\n",
        "train_dir = \"./data/test-20250112T065939Z-001/test\"\n",
        "test_dir = \"./data/train-20250112T065955Z-001/train\"\n",
        "\n",
        "train_dataset = DeepfakeDataset(train_dir, transform=transform)\n",
        "test_dataset = DeepfakeDataset(test_dir, transform=transform)"
      ],
      "metadata": {
        "id": "Ra5b9CIjd-H5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create loaders\n",
        "def collate_fn(batch):\n",
        "    return Batch.from_data_list(batch)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "sh6qJBiI5yH5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop -----------------------------------------------------\n",
        "print(\"Starting training...\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}...\")\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(batch.x, batch.edge_index, batch.batch)\n",
        "        loss = criterion(outputs, batch.y)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"\\nEpoch {epoch + 1} finished — Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc72oWPK54d1",
        "outputId": "c9edf1e7-5aa5-4e53-e823-101b729f209c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "\n",
            "Epoch 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 finished — Loss: 0.5576\n",
            "\n",
            "Epoch 2/5...\n",
            "\n",
            "Epoch 2 finished — Loss: 0.4643\n",
            "\n",
            "Epoch 3/5...\n",
            "\n",
            "Epoch 3 finished — Loss: 0.4169\n",
            "\n",
            "Epoch 4/5...\n",
            "\n",
            "Epoch 4 finished — Loss: 0.4034\n",
            "\n",
            "Epoch 5/5...\n",
            "\n",
            "Epoch 5 finished — Loss: 0.3741\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation --------------------------------------------------------\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        outputs = model(batch.x, batch.edge_index, batch.batch)\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).long()\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch.y.long().cpu().numpy())\n",
        "\n",
        "# Metrics\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "prec = precision_score(all_labels, all_preds, zero_division=0)\n",
        "rec = recall_score(all_labels, all_preds, zero_division=0)\n",
        "f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "conf_mat = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nTest Metrics:\")\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall:    {rec:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "4rjpUus-7I-f",
        "outputId": "abe900ae-290b-4e03-e42b-d871ec641679"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics:\n",
            "Accuracy:  0.6033\n",
            "Precision: 0.8953\n",
            "Recall:    0.4724\n",
            "F1 Score:  0.6185\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "output_dir='.result/deepfake_model_clip'\n",
        "os.makedirs(output_dir, exist_ok=True)  # 디렉토리 없으면 생성\n",
        "\n",
        "save_path = os.path.join('', \"deepfake_gnn_model.pth\")\n",
        "torch.save(model.state_dict(), save_path)   # 모델 파라미터 저장\n",
        "print(f\"Model saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SyXiCXn9YGV",
        "outputId": "ecf70693-cd77-4306-a7e6-fd151a8ab4f4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to .result/deepfake_model_clip/deepfake_gnn_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import upload_file\n",
        "from huggingface_hub import create_repo, upload_file\n",
        "# 1. 레포지토리 생성 (없으면 새로 만듦)\n",
        "repo_id = \"dmsrud/deepfake_model_clip\"\n",
        "create_repo(repo_id, exist_ok=True)  # exist_ok=True면 이미 있어도 에러 안 남\n",
        "\n",
        "torch.save(model.state_dict(), \"deepfake_gnn_model.pth\")\n",
        "\n",
        "# 2. Hub에 업로드\n",
        "repo_id = \"dmsrud/deepfake_model_clip\"\n",
        "upload_file(\n",
        "    path_or_fileobj=\"deepfake_gnn_model.pth\",\n",
        "    path_in_repo=\"deepfake_gnn_model.pth\",\n",
        "    repo_id=repo_id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161,
          "referenced_widgets": [
            "4b67bee8bdce4eb1b00c465244707529",
            "d9dd3f794d7f422f995acbf68c511c4a",
            "f7b9edc064c2408d8d545b4757f0ed11",
            "b302a2fc5d4b4ce99a7d548454dde3f6",
            "56785b1047034e038222333c25c958b1",
            "acabe1376f9b4b8c83e11aea91ecf5e5",
            "18d5711367794c7c9442325688b5556c",
            "157a5d4505b546f7b61059a63d983952",
            "7a02bef9c46f4674b34a980ea53b6959",
            "a5099ec985aa47e3b0b711525e844919",
            "c72496fd202c451091240cae553924b5"
          ]
        },
        "id": "XL22u18pA679",
        "outputId": "ef9dabc4-faf7-4a0a-d22f-0d28781ec485"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "deepfake_gnn_model.pth:   0%|          | 0.00/793k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b67bee8bdce4eb1b00c465244707529"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/dmsrud/deepfake_model_clip/commit/9ace14604e5771dbe45821002ab41564cfd0ab16', commit_message='Upload deepfake_gnn_model.pth with huggingface_hub', commit_description='', oid='9ace14604e5771dbe45821002ab41564cfd0ab16', pr_url=None, repo_url=RepoUrl('https://huggingface.co/dmsrud/deepfake_model_clip', endpoint='https://huggingface.co', repo_type='model', repo_id='dmsrud/deepfake_model_clip'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/Colab Notebooks/인사교_8월미니프로젝트/data/test-20250112T065939Z-001/test/fake/0.jpg"
      ],
      "metadata": {
        "id": "Opg3ehGKG__b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "#cap = cv2.VideoCapture(\"../인사교_Agent/UCF101_subset/test/BenchPress/v_BenchPress_g05_c02.avi\")\n",
        "cap = cv2.VideoCapture(\"./data/test-20250112T065939Z-001/test/fake/0.jpg\")\n",
        "frames = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    # OpenCV는 BGR이므로 RGB로 변환\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frames.append(frame)\n",
        "\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "oS1J5lkAEY-P"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# CLIP 모델이나 CNN에 맞춘 transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),           # NumPy 배열 → PIL 이미지\n",
        "    transforms.Resize((224, 224)),     # 모델 입력 크기\n",
        "    transforms.ToTensor(),             # PIL → Tensor (C,H,W)\n",
        "    transforms.Normalize(              # CLIP용 정규화 (예시)\n",
        "        mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "        std=[0.26862954, 0.26130258, 0.27577711]\n",
        "    )\n",
        "])\n",
        "\n",
        "frame_tensors = [transform(frame) for frame in frames]  # 리스트 of tensors\n",
        "\n",
        "# 배치 차원 추가 (N, C, H, W)\n",
        "frame_tensors = torch.stack(frame_tensors)\n"
      ],
      "metadata": {
        "id": "omFUfdxIEEvb"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/Colab Notebooks/인사교_8월미니프로젝트/deepfake-detection-clip-gnn.ipynb"
      ],
      "metadata": {
        "id": "MnayLY6iGDOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPModel, CLIPProcessor\n",
        "\n",
        "# 학습한 모델 허깅스페이스에서 가져오기\n",
        "clip_model = CLIPModel.from_pretrained(\"dmsrud/deepfake_model_clip\")\n",
        "clip_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # 배치 입력\n",
        "    features = clip_model.get_image_features(frame_tensors)  # (num_frames, feature_dim)\n"
      ],
      "metadata": {
        "id": "t27n_CLDEjTF"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# 노드(feature) 정의\n",
        "x = features  # shape = (num_frames, feature_dim)\n",
        "\n",
        "# edge_index 생성 (간단한 순차 연결: frame i → frame i+1)\n",
        "num_frames = x.size(0)\n",
        "edge_index = torch.tensor(\n",
        "    [[i for i in range(num_frames-1)] + [i+1 for i in range(num_frames-1)],\n",
        "     [i+1 for i in range(num_frames-1)] + [i for i in range(num_frames-1)]],\n",
        "    dtype=torch.long\n",
        ")  # shape = (2, 2*(num_frames-1))\n",
        "\n",
        "# PyG 데이터 객체 생성\n",
        "graph = Data(x=x, edge_index=edge_index)\n"
      ],
      "metadata": {
        "id": "nYagqSkQEqEU"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "\n",
        "class DeepfakeGNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fc = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index).relu()\n",
        "        # 모든 노드 feature 평균(pooling)\n",
        "        x = global_mean_pool(x, torch.zeros(x.size(0), dtype=torch.long))\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# 모델 초기화\n",
        "gnn_model = DeepfakeGNN(in_channels=features.size(1), hidden_channels=256, out_channels=2)\n",
        "gnn_model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrIq-QJ5FSxN",
        "outputId": "fd147fe9-c391-46d2-d631-36c09118eb97"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepfakeGNN(\n",
              "  (conv1): GCNConv(512, 256)\n",
              "  (conv2): GCNConv(256, 256)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측 잘 되는데??\n"
      ],
      "metadata": {
        "id": "PoxjN1PuHLqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out = gnn_model(graph)  # shape = (batch=1, num_classes)\n",
        "    pred = torch.argmax(out, dim=1)\n",
        "    print(\"예측 클래스:\", pred.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdKi0bpbFVXY",
        "outputId": "6549f564-e1c5-45f0-fe61-7bb2aa79ef49"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 클래스: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iCtLklTeHNiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out = gnn_model(graph)  # shape = (batch=1, num_classes)\n",
        "    pred = torch.argmax(out, dim=1)\n",
        "    print(\"예측 클래스:\", pred.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohjOny4FHJt7",
        "outputId": "48510137-b4e0-4d6d-c7a3-a83a214ca391"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 클래스: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 맵 정의\n",
        "class_map = {0: False, 1: True}\n",
        "\n",
        "# pred가 Tensor인 경우\n",
        "pred_label = class_map[pred.item()]\n",
        "\n",
        "print(\"예측 클래스:\", pred_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOSIpKoVFl1X",
        "outputId": "824bddc5-af97-412a-d0ca-cbe5c1f06767"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 클래스: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "baFJhLfVGiHW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}