1) 컨테이너 볼륨생성

1. Volume 이름 생성
2. Storage Class 선택
3. Access Mode - ReadWriteMany로 선택
4. Volume Capacity - 0.5TB로 설정(514Gi)
5. Add Metadata 설정은 skip
6. create

2) 컨테이너 생성
1)  Name 설정
2) Container Settings 
docker hub - pytorch 검색해서 pytorch/pyotorch 검색 후 
pytorch 2.8.0,cuda 12.8 다운
pytorch/pytorch:2.8.0-cuda12.8-cudnn9-runtime
3)Advanced Settings
cpu,gpu 함께 쓰면 절반으로 나눠서 세팅(4 – 427648 MiB – 27648 MiB)하고 gpu는 한 계정만 1로
Port Settings -Protocol: TCP, port: 22
3)create
4) Storage Mount Volume
만든 Volume 선택하고 Read and Write 모드로 바꾸고 /data 밑에 저장
5) 지속적인 커널로 만들기 위해 Yaml 파일 수정
volumne mount에 command: ["bash", "-c", "sleep infinity"] 추가
6)create
7) running 상태가 되면 컨테이너 완성!

2) 컨테이너 루트 계정 생성
1. 컨테이너 터미널에서 passwd로 루트 계정 비밀번호 생성
2. adduser 사용자id 로 user 계정 추가

3)ssh 서버 생성
apt update 
apt install openssh-server -y
mkdir /run/sshd
/usr/sbin/sshd

4) 서비스 생성 - 외부에서 접근할 수 있는 포트 번호(31949) 생성
1. Specify Workload 생성
2. Ports에 Protocol-TCP, Name-tcp-22, Container Port-22, Service Port-22로 설정
3.  Specify Workload를 생성한 컨테이너로 설정
4.  External Access 선택 - Access Mode를 NodePort로 설정

5) powershell에서 접근
1. ssh han@210.125.70.71 -p 31949
Q. fingerprint 생성? yes
passwd 입력

% gpu 확인 %
nvidia-smi

su - 사용자 계정바꾸기, su만 썼을 경우, 루트 계정으로 바꿈
cd ../../ 루트 계정에서 상위 폴더로 이동 
conda는 opt 밑에 설치되어 있음
기본으로 깔려져있는 python3로 torch 사용 x
-> conda에 깔려 있는 python 인터프리터 사용
환경변수 설정
apt-get install vim -  환경변수 설치
vim ~/.bashrc
i 누르고 INSERT 모드 뜨면 제일 아래로 이동 후
export PATH="/opt/conda/bin $PATH"
enter로 다음 줄로 바꾼 후 esc 누르고 :wq 로 빠져나오기
bash 파일 재인식 - source ~/.bashrc
그 후 python 치면 conda 아래의 python 사용 가능
컨테이너에 pytorch 설치