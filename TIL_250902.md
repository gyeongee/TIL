### 이미지 분류
이미지에 레이블 또는 클래스 할당

- 데이터셋 구성
  Dataset({
    features: ['image', 'label'],
    num_rows: 5000
})

```
#### 훈련/검증 데이터 분리
dataset=dataset.train_test_split(test_size=0.2)
# 결과
<!-- DatasetDict({
    train: Dataset({
        features: ['image', 'label'],
        num_rows: 4000
    })
    test: Dataset({
        features: ['image', 'label'],
        num_rows: 1000
    })
}) -->
```
```
# 라벨을 정수로 매핑, 정수를 라벨로 매핑
labels = dataset["train"].features["label"].names

# 인덱스 -> 라벨 문자(디코딩 맵핑 테이블)
id2label = {idx:label for idx,label in enumerate(labels)}
# 라벨 -> 인덱스(인코딩 맵핑 테이블)
label2id = {label : idx for idx,label in enumerate(labels)}
print(id2label)
# 결과 :{0: 'apple_pie', 1: 'baby_back_ribs', 2: 'baklava', 3: 'beef_carpaccio'...}
print(label2id)
# 결과 : {'apple_pie': 0, 'baby_back_ribs': 1, 'baklava': 2, 'beef_carpaccio': 3..}
```
```
# 전처리
# RandomResizedCrop : 임의로 이미지 크기를 변경하고 Crop
# Compose : 여러 가지의 이미지 변환 함수를 순서대로 처리
# Normalize : 정규화 (평균, 표준편차)
# ToTensor : numpy 타입을 tensor 타입으로 변경

from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor

# 입력 이미지 크기 설정 (삼항 연산자)
size = (
    # 이미지의 짧은 변을 기준으로 크기를 설정
    image_processor.size["shortest_edge"]

    # shortest_edge가 있다면 (짧은 변을 기준으로 할 때)
    if "shortest_edge" in image_processor.size
    # 가로, 세로 크기를 그대로 원할 때
    else (image_processor.size["height"], image_processor.size["width"])
)

print(size)

# 이미지 평균과 표준 편차로 정규화
# 모델은 학습 당시 특정 분포(예: 평균 0, 표준편차 1)로 정규화된 이미지를 입력
# 모델에 입력될 이미지를 모델이 기대하는 분포에 맞추기 위해 사용
# 다양한 데이터셋에서 입력 스케일이 다르기 때문에, 정규화를 통해 입력 일관성을 확보
normalize = Normalize(mean=image_processor.image_mean,
                      std=image_processor.image_std)

# 이미지를 무작위로 자르고 size 크기로 리사이즈 후에 텐서로 변환하고 정규화 (데이터 증강 효과)
_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])
```
```
def pre_process(example):
    examples["pixel_values"]=[_transforms(img.convert("RGB")) for img in examples["image"]]
# 이미지를 불러와서 RGB로 변환한 후 설정한 전처리 순서에 따라 전처리 수행
    # 원래 image 컬럼 삭제
    del examples["image"]

    return examples
    dataset2 = dataset.map(pre_process, batched=True)
```
```
# 평가 모델 로드
import evaluate
accuracy = evaluate.load("accuracy")
```

```
# 평가 함수 정의
import numpy as np

def compute_metircs(eval_pred):
    # 예측 확률과 실제 라벨을 분리
    logits,labels = eval_pred

    # 확률값에서 최대값인 인덱스를 반환
    predictions = np.argmax(logits,axis=1)

    # 예측 라벨괎과 실제 라벨값을 비교하여 정확도를 반환
    return accuracy.compute(predictions=predictions, references=lables)
```

```
# 모델로드
from transformers import AutoModelForImageClassification

model = AutoModelForImageClassification.from_pretrained(
    # 모델의 명칭
    checkpoint,
    # 라벨의 클래스 수
    num_labels=len(labels)
    # 인코딩 및 디코딩 맵핑 데이터
    id2label =id2label,
    label2id=label2id
)
```

```
#훈련설정 및 훈련
from transformers import DefaultDataCollator

# 배치단위로 데이터를 모아주는 기
data_collater = DefaultDataCollator()
```