##### 1-3. onnx 파일로 모델 테스트한 결과 Gradio를 이용하여 웹서비스 구현
```
import gradio as gr
import torch
import torchvision
from torchvision.transforms import Resize, Normalize
import numpy as np
import onnxruntime as ort

# -------------------------------
# VideoMAE ONNX pipeline
class VideoMAE_ONNX_Pipeline:
    def __init__(self, onnx_path, num_frames, resize_to, mean, std, id2label):
        self.ort_sess = ort.InferenceSession(onnx_path)
        self.num_frames = num_frames
        self.resize_to = resize_to
        self.mean = mean
        self.std = std
        self.id2label = id2label

        self.resize = Resize(resize_to)
        self.normalize = Normalize(mean=mean, std=std)

    def __call__(self, video_path):
        # 1. 비디오 읽기 [T,H,W,C]
        video, _, _ = torchvision.io.read_video(video_path, pts_unit='sec')
        video = video.float()

        # 2. 프레임 샘플링 (균등)
        T = video.shape[0]
        indices = torch.linspace(0, T - 1, steps=self.num_frames).long()
        video = video[indices]

        # 3. 채널 순서 변경 [T,H,W,C] -> [T,C,H,W]
        video = video.permute(0, 3, 1, 2)

        # 4. Resize + Normalize
        video = torch.stack([self.normalize(self.resize(frame)) for frame in video])

        # 5. 배치 차원 추가 [B,T,C,H,W]
        video = video.unsqueeze(0)

        # 6. ONNX 입력
        ort_inputs = {"pixel_values": video.numpy().astype(np.float32)}

        # 7. 추론
        logits = self.ort_sess.run(None, ort_inputs)[0]
        pred_id = np.argmax(logits, axis=1)[0]

        return self.id2label[pred_id]

# -------------------------------
# 설정
onnx_path = "./dmsrud/anomalous_behavior_video_cls_model/video_cls_model.onnx"
num_frames = 16
resize_to = (224, 224)
mean = [0.485, 0.456, 0.406]
std  = [0.229, 0.224, 0.225]
id2label = {
    0: "assult", 1: "datefight", 2: "robbery", 3: "burglary", 4: "trespass",
    5: "wander", 6: "vandalism", 7: "fight", 8: "dump", 9: "swoon", 10: "kidnap"
}

pipeline = VideoMAE_ONNX_Pipeline(onnx_path, num_frames, resize_to, mean, std, id2label)

# -------------------------------
# Gradio용 함수
def analyze_video(video_file):
    label = pipeline(video_file)
    message = f"{label} 값이 탐지되었습니다. 출동합니다 🚨"
    return message

# -------------------------------
# Gradio 인터페이스 (버튼 추가)
with gr.Blocks() as demo:
    gr.Markdown("## 🚓 비디오 이상행동 탐지 시스템")

    with gr.Row():
        video_input = gr.Video(label="비디오 업로드")

    with gr.Row():
        btn = gr.Button("탐지 시작")

    with gr.Row():
        message_output = gr.Textbox(label="탐지 결과")
        # video_output = gr.Video(label="입력 비디오")

    # 버튼 클릭 시 분석 실행
    btn.click(fn=analyze_video, inputs=video_input, outputs=[message_output])#, video_output

demo.launch(share=True)
```